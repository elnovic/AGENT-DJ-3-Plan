
# ğŸµ TON DJ IA COMPLET - 3 AGENTS INTELLIGENTS
# ExportÃ© depuis Google Colab

import torch
import torch.nn as nn
from transformers import AutoModel, AutoTokenizer
import numpy as np
import time
from typing import Dict, List
from collections import deque

# ==================== AGENT 1 ====================
class FunctionalMusicAgent(nn.Module):
    def __init__(self):
        super().__init__()
        self.base_model = AutoModel.from_pretrained("microsoft/deberta-v3-small")
        self.classifier = nn.Sequential(
            nn.Linear(768 + 4, 256), nn.ReLU(),
            nn.Linear(256, 128), nn.ReLU(), 
            nn.Linear(128, 1), nn.Sigmoid()
        )
    
    def forward(self, input_ids, attention_mask, context_features):
        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)
        pooled = outputs.last_hidden_state[:, 0, :]
        combined = torch.cat([pooled, context_features], dim=1)
        return {"final_score": self.classifier(combined)}

class Agent1_MusicCurator:
    def __init__(self):
        self.expert_system = MusicExpertSystem()
        self.ml_model = None
        self.tokenizer = AutoTokenizer.from_pretrained("microsoft/deberta-v3-small")
        
    def load_ml_model(self, model_path):
        try:
            model = FunctionalMusicAgent()
            model.load_state_dict(torch.load(f"{model_path}/pytorch_model.bin"))
            model.eval()
            self.ml_model = model
            print("âœ… ModÃ¨le ML chargÃ©")
        except:
            print("âš ï¸  Utilisation du systÃ¨me expert")
    
    def predict(self, track_info, context="soiree", use_ml=False):
        if use_ml and self.ml_model:
            return self._ml_predict(track_info, context)
        else:
            return self.expert_system.predict_score(track_info, context)
    
    def _ml_predict(self, track_info, context):
        try:
            text = f"Titre: {track_info['name']}. Artistes: {', '.join(track_info['artists'])}."
            encoding = self.tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)
            
            context_map = {"soiree": 0, "diner": 1, "afterwork": 2, "relax": 3}
            context_tensor = torch.zeros(1, 4)
            context_tensor[0, context_map[context]] = 1.0
            
            with torch.no_grad():
                outputs = self.ml_model(
                    input_ids=encoding['input_ids'],
                    attention_mask=encoding['attention_mask'],
                    context_features=context_tensor
                )
            
            score = outputs['final_score'].item()
            return {'score': score, 'recommendation': self.expert_system.get_recommendation(score)}
        except:
            return self.expert_system.predict_score(track_info, context)

# ==================== AGENT 2 ====================
class Agent2_AudioPlayer:
    def __init__(self):
        self.current_track = None
        self.playlist = []
        self.is_playing = False
        
    def load_playlist(self, tracks):
        self.playlist = tracks
        self.playlist.sort(key=lambda x: x.get('score', 0), reverse=True)
        print(f"ğŸµ Playlist: {len(tracks)} morceaux")
    
    def play_track(self, track_info):
        self.current_track = track_info
        self.is_playing = True
        print(f"ğŸµ NOW PLAYING: {track_info['name']} - {track_info['artists'][0]}")
        return True
    
    def auto_mix_playlist(self, context="soiree"):
        if not self.playlist:
            return []
        
        mixed_playlist = []
        current_track = None
        
        for track in self.playlist[:10]:
            if current_track is None:
                mixed_playlist.append(track)
                current_track = track
            else:
                mixed_playlist.append(track)
                current_track = track
        
        print(f"ğŸ›ï¸  Mix crÃ©Ã©: {len(mixed_playlist)} morceaux")
        return mixed_playlist

# ==================== AGENT 3 ====================
class Agent3_AudienceAnalyzer:
    def __init__(self):
        self.audience_metrics = {"energy_level": 0.5, "engagement": 0.5, "mood": "neutral"}
        self.metric_history = deque(maxlen=10)
    
    def simulate_audience_reaction(self, track_features, context):
        track_energy = track_features.get('energy', 0.5)
        
        # Simulation rÃ©aliste
        energy_reaction = track_energy * 1.2 if context == "soiree" else track_energy
        energy_reaction = max(0.1, min(1.0, energy_reaction + np.random.normal(0, 0.1)))
        
        reaction = {
            "energy_level": energy_reaction,
            "engagement": track_features.get('danceability', 0.5),
            "mood": "joyeux" if track_features.get('valence', 0.5) > 0.6 else "content",
            "applause_detected": np.random.random() < 0.3,
            "cheering_detected": np.random.random() < 0.2
        }
        
        self.metric_history.append(reaction)
        return reaction

# ==================== SYSTÃˆMES ====================
class MusicExpertSystem:
    def predict_score(self, track_info, context):
        energy = track_info.get('energy', 0.5)
        danceability = track_info.get('danceability', 0.5)
        
        if context == "soiree":
            score = energy * 0.6 + danceability * 0.4
        elif context == "diner":
            score = (1 - energy) * 0.3 + danceability * 0.3 + 0.4
        else:
            score = (energy + danceability) / 2
            
        return {'score': max(0.1, min(0.99, score)), 'recommendation': 'TEST'}
    
    def get_recommendation(self, score):
        return "âœ… Recommandation systÃ¨me expert"

class CompleteDJSystem:
    def __init__(self):
        self.agent1 = Agent1_MusicCurator()
        self.agent2 = Agent2_AudioPlayer()
        self.agent3 = Agent3_AudienceAnalyzer()
        print("ğŸ›ï¸  SYSTÃˆME DJ 3-AGENTS INITIALISÃ‰")
    
    def adaptive_dj_session(self, context, duration_minutes=5):
        print(f"ğŸª SESSION DJ - {context.upper()}")
        
        # Utilise des morceaux de test
        test_tracks = [
            {"name": "Blinding Lights", "artists": ["The Weeknd"], "energy": 0.8, "danceability": 0.8, "valence": 0.7},
            {"name": "Don't Start Now", "artists": ["Dua Lipa"], "energy": 0.8, "danceability": 0.9, "valence": 0.8},
        ]
        
        # Score les morceaux
        for track in test_tracks:
            result = self.agent1.predict(track, context)
            track['score'] = result['score']
        
        # CrÃ©e le mix
        self.agent2.load_playlist(test_tracks)
        mixed = self.agent2.auto_mix_playlist(context)
        
        # Simule la session
        tracks_played = 0
        for track in mixed[:3]:  # Limite Ã  3 morceaux pour le test
            self.agent2.play_track(track)
            reaction = self.agent3.simulate_audience_reaction(track, context)
            print(f"   ğŸ“Š Audience: Ã©nergie {reaction['energy_level']:.2f}")
            tracks_played += 1
        
        print(f"âœ… Session terminÃ©e: {tracks_played} morceaux")
        return tracks_played

# ==================== LANCEUR ====================
def demarrer_session_dj():
    print("ğŸš€ LANCEMENT DE TON DJ IA COMPLET")
    print("=" * 50)
    
    systeme = CompleteDJSystem()
    
    # Test avec diffÃ©rents contextes
    for contexte in ["soiree", "diner", "afterwork"]:
        print(f"\nğŸª TEST {contexte.upper()}...")
        systeme.adaptive_dj_session(contexte, duration_minutes=1)
    
    print("\nğŸ‰ TON DJ IA EST COMPLÃˆTEMENT FONCTIONNEL!")
    return True

if __name__ == "__main__":
    demarrer_session_dj()
